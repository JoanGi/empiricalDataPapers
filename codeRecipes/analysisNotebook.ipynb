{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting and parsing sources (stored as a list of Document objects in strings)\n",
    "sources = pd.read_excel(\"../results/sources.xlsx\")\n",
    "dimensions = {\n",
    "\"uses_uses_sources\",\n",
    "\"uses_data_limits_sources\",\n",
    "\"uses_ml_approach_sources\",\n",
    "\"uses_represents_people_sources\",\n",
    "\"uses_biases_sources\",\n",
    "\"uses_privacy_sources\",\n",
    "\"uses_sensitivity_sources\",\n",
    "\"uses_maintenance_policies_sources\",\n",
    "\"collection_explanation_sources\",\n",
    "\"collection_team_sources\",\n",
    "\"collection_labour_sources\",\n",
    "\"collection_team_demographic_sources\",\n",
    "\"collection_target_demographics_sources\",\n",
    "\"collection_speakers_demographics_sources\",\n",
    "\"collection_sources_sources\",\n",
    "\"collection_infrastructure_sources\",\n",
    "\"annotation_explanation_sources\",\n",
    "\"annotation_team_demographi_sources\",\n",
    "\"annotation_infrastructure_sources\",\n",
    "\"annotation_validation_methods_sources\",\n",
    "}\n",
    "source_sections = []\n",
    "# Loading raw data\n",
    "rawData = pd.read_excel(\"../results/FullStudyAnalysis.xlsx\", sheet_name=\"Raw Data\")\n",
    "# Joining sources to raw data\n",
    "mergedData = rawData.merge(sources, on=\"doi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dimensions subsets from our overall raw data and by journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by jorunal\n",
    "mergedData_SD = mergedData.query(\"journal_x == 'SData'\")\n",
    "mergedData_Dbrief = mergedData.query(\"journal_x == 'DBrief'\")\n",
    "# Is using an ML approach\n",
    "subsetML = mergedData.query(\"uses_ml_approach_bool == 'Yes'\")\n",
    "subsetML_SD = subsetML.query(\"journal_x == 'SData'\")\n",
    "subsetML_Dbrief = subsetML.query(\"journal_x == 'DBrief'\")\n",
    "# Use data limits\n",
    "subsetLimits = mergedData.query(\"uses_data_limits.str.contains('Yes,*')\")\n",
    "subsetLimits_SD = subsetLimits.query(\"journal_x == 'SData'\")\n",
    "subsetLimits_Dbrief = subsetLimits.query(\"journal_x == 'DBrief'\")\n",
    "# Social Concerns subset\n",
    "strng = \"<class 'str'>\"\n",
    "subsetPeople = mergedData.query(\"uses_biases_bool != @strng\")\n",
    "subsetSocial = mergedData.query(\"uses_biases_bool == 'Yes'\")\n",
    "subsetSocial_SD = subsetSocial.query(\"journal_x == 'SData'\")\n",
    "subsetSocial_Dbrief = subsetSocial.query(\"journal_x == 'DBrief'\")\n",
    "# Collection team demographics\n",
    "subsetCollectionTeam = mergedData.query(\"collection_team_demographic.str.contains('Yes,*')\")\n",
    "subsetCollectionTeam_SD = subsetCollectionTeam.query(\"journal_x == 'SData'\")\n",
    "subsetCollectionTeam_Dbrief = subsetCollectionTeam.query(\"journal_x == 'DBrief'\")\n",
    "# Collection target demographics\n",
    "subsetCollectionTargetDemographics = mergedData.query(\"collection_target_demographics.str.contains('Yes,*',na=False)\")\n",
    "subsetCollectionTargetDemographics_SD = subsetCollectionTargetDemographics.query(\"journal_x == 'SData'\")\n",
    "subsetCollectionTargetDemographics_Dbrief = subsetCollectionTargetDemographics.query(\"journal_x == 'DBrief'\")\n",
    "# Collection speakers demographics\n",
    "subsetCollectionSpeakersDemographics = mergedData.query(\"collection_speakers_demographics.str.contains('Yes,*',na=False)\")\n",
    "subsetCollectionSpeakersDemographics_SD = subsetCollectionSpeakersDemographics.query(\"journal_x == 'SData'\")\n",
    "subsetCollectionSpeakersDemographics_Dbrief = subsetCollectionSpeakersDemographics.query(\"journal_x == 'DBrief'\")\n",
    "# Annotation profile\n",
    "subsetAnntationTeam = mergedData.query(\"annotation_team_demograaphic.str.contains('Yes,*',na=False)\")\n",
    "subsetAnntationTeam_SD = subsetAnntationTeam.query(\"journal_x == 'SData'\")\n",
    "subsetAnntationTeam_Dbrief = subsetAnntationTeam.query(\"journal_x == 'DBrief'\")\n",
    "# Annotation infrastructure\n",
    "subsetAnntationInfrastructure = mergedData.query(\"annotation_infrastructure.str.contains('Yes,*',na=False)\")\n",
    "subsetAnntationInfrastructure_SD = subsetAnntationInfrastructure.query(\"journal_x == 'SData'\")\n",
    "subsetAnntationInfrastructure_Dbrief = subsetAnntationInfrastructure.query(\"journal_x == 'DBrief'\")\n",
    "# Annotation validation\n",
    "subsetAnntationValidation = mergedData.query(\"annotation_validation_methods.str.contains('Yes,*',na=False)\")\n",
    "subsetAnntationValidation_SD = subsetAnntationValidation.query(\"journal_x == 'SData'\")\n",
    "subsetAnntationValidation_Dbrief = subsetAnntationValidation.query(\"journal_x == 'DBrief'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the sections of each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections(dataPapersList, dimension):\n",
    "    sections = []\n",
    "    for idx, papers in dataPapersList.iterrows():\n",
    "        if  isinstance(papers[dimension],str):\n",
    "            documents = eval(papers[dimension])\n",
    "            for document in documents:\n",
    "                    if dimension == \"uses_uses_sources\":\n",
    "                        sections.insert(0,document[0].metadata['source'])\n",
    "                    else:\n",
    "                        sections.insert(0,document.metadata['source'])\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section extraction; overall and by SD and Dbrief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses\n",
    "sectionsUses = extract_sections(mergedData,\"uses_uses_sources\")\n",
    "sectionsUses_SD = extract_sections(mergedData_SD,\"uses_uses_sources\")\n",
    "sectionsUses_DBrief = extract_sections(mergedData_Dbrief,\"uses_uses_sources\")\n",
    "# MLapproach\n",
    "sectionsMLapproach = extract_sections(subsetML,\"uses_ml_approach_sources\")\n",
    "sectionsMLapproach_SD = extract_sections(subsetML_SD,\"uses_ml_approach_sources\")\n",
    "sectionsMLapproach_DBrief = extract_sections(subsetML_Dbrief,\"uses_ml_approach_sources\")\n",
    "# Limits\n",
    "sectionsLimits = extract_sections(subsetLimits,\"uses_data_limits_sources\")\n",
    "sectionsLimits_SD = extract_sections(subsetLimits_SD,\"uses_data_limits_sources\")\n",
    "sectionsLimits_Dbrief = extract_sections(subsetLimits_Dbrief,\"uses_data_limits_sources\")\n",
    "# Social\n",
    "sectionsSocial = extract_sections(subsetSocial,\"uses_biases_sources\")\n",
    "sectionsSocial_SD = extract_sections(subsetSocial_SD,\"uses_biases_sources\")\n",
    "sectionsSocial_DBrief = extract_sections(subsetSocial_Dbrief,\"uses_biases_sources\")\n",
    "# Collection\n",
    "sectionsCollection = extract_sections(mergedData,\"collection_explanation_sources\")\n",
    "sectionsCollection_SD = extract_sections(mergedData_SD,\"collection_explanation_sources\")\n",
    "sectionsCollection_Dbrief = extract_sections(mergedData_Dbrief,\"collection_explanation_sources\")\n",
    "# Col Team\n",
    "sectionsColTeam = extract_sections(subsetCollectionTeam,\"collection_team_demographic_sources\")\n",
    "sectionsColTeam_SD = extract_sections(subsetCollectionTeam_SD,\"collection_team_demographic_sources\")\n",
    "sectionsColTeam_Dbrief = extract_sections(subsetCollectionTeam_Dbrief,\"collection_team_demographic_sources\")\n",
    "# Col target\n",
    "sectionsColTarget = extract_sections(subsetCollectionTargetDemographics,\"collection_target_demographics_sources\")\n",
    "sectionsColTarget_SD = extract_sections(subsetCollectionTargetDemographics_SD,\"collection_target_demographics_sources\")\n",
    "sectionsColTarget_Dbrief = extract_sections(subsetCollectionTargetDemographics_Dbrief,\"collection_target_demographics_sources\")\n",
    "# Col Sources\n",
    "sectionsCollectionSources = extract_sections(mergedData,\"collection_sources_sources\")\n",
    "sectionsCollectionSources_SD = extract_sections(mergedData_SD,\"collection_sources_sources\")\n",
    "sectionsCollectionSources_Dbrief = extract_sections(mergedData_Dbrief,\"collection_sources_sources\")\n",
    "# Annotation\n",
    "sectionsAnnotation = extract_sections(mergedData,\"annotation_explanation_sources\")\n",
    "sectionsAnnotation_SD = extract_sections(mergedData_SD,\"annotation_explanation_sources\")\n",
    "sectionsAnnotation_Dbrief = extract_sections(mergedData_Dbrief,\"annotation_explanation_sources\")\n",
    "\n",
    "# Annotation team\n",
    "sectionsAnnTeam = extract_sections(subsetAnntationTeam,\"annotation_team_demographi_sources\")\n",
    "sectionsAnnTeam_SD = extract_sections(subsetAnntationTeam_SD,\"annotation_team_demographi_sources\")\n",
    "sectionsAnnTeam_Dbrief = extract_sections(subsetAnntationTeam_Dbrief,\"annotation_team_demographi_sources\")\n",
    "\n",
    "# Annotation infrastructure\n",
    "sectionsAnnInfr = extract_sections(subsetAnntationInfrastructure,\"annotation_infrastructure_sources\")\n",
    "sectionsAnnInfr_SD = extract_sections(subsetAnntationInfrastructure_SD,\"annotation_infrastructure_sources\")\n",
    "sectionsAnnInfr_Dbrief = extract_sections(subsetAnntationInfrastructure_Dbrief,\"annotation_infrastructure_sources\")\n",
    "\n",
    "# Annotation Validation\n",
    "sectionsAnnVal = extract_sections(subsetAnntationValidation,\"annotation_validation_methods_sources\")\n",
    "sectionsAnnVal_SD = extract_sections(subsetAnntationValidation_SD,\"annotation_validation_methods_sources\")\n",
    "sectionsAnnVal_Dbrief = extract_sections(subsetAnntationValidation_Dbrief,\"annotation_validation_methods_sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify by sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joangi/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "classifier = transformers.pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "sdataRequiredSections = [\n",
    "\"Title\",\n",
    "\"Abstract\",\n",
    "\"Background & Summary\",\n",
    "\"Methods\",\n",
    "\"Data Records\",\n",
    "\"Technical Validation\",\n",
    "\"Usage Notes\",\n",
    "\"Code Availability\",\n",
    "\"References\",\n",
    "\"Author Contributions\",\n",
    "\"Competing Interests\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLabels(sections):\n",
    "    finalSections = []\n",
    "    for idx , section in enumerate(sections):\n",
    "        if section:\n",
    "            resultClass  = classifier(section, sdataRequiredSections)\n",
    "            if resultClass['scores'][0] > 0.4:\n",
    "                print(\"changed\")\n",
    "                sections[idx] = resultClass['labels'][0]\n",
    "            # save the result\n",
    "    return finalSections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(sectionsUses_SD).value_counts()\n",
    "counts.to_excel(\"sectionCounts.xlsx\", sheet_name=\"Uses\")\n",
    "\n",
    "# Uses\n",
    "countsUses = pd.DataFrame(extract_sections(mergedData,\"uses_uses_sources\")).value_counts()\n",
    "countsUses_SD = pd.DataFrame(extract_sections(mergedData_SD,\"uses_uses_sources\")).value_counts()\n",
    "countsUses_DBrief = pd.DataFrame(extract_sections(mergedData_Dbrief,\"uses_uses_sources\")).value_counts()\n",
    "\n",
    "# MLapproach\n",
    "countsMLapproach = pd.DataFrame(extract_sections(subsetML,\"uses_ml_approach_sources\")).value_counts()\n",
    "countsMLapproach_SD = pd.DataFrame(extract_sections(subsetML_SD,\"uses_ml_approach_sources\")).value_counts().to_excel(\"mlapproaches.xlsx\")\n",
    "countsMLapproach_Dbrief = pd.DataFrame(extract_sections(subsetML_Dbrief,\"uses_ml_approach_sources\")).value_counts()\n",
    "\n",
    "# Limits\n",
    "countsLimits = pd.DataFrame(extract_sections(subsetLimits,\"uses_data_limits_sources\")).value_counts()\n",
    "countsLimits_SD = pd.DataFrame(extract_sections(subsetLimits_SD,\"uses_data_limits_sources\")).value_counts().to_excel(\"limits.xlsx\")\n",
    "countsLimits_Dbrief = pd.DataFrame(extract_sections(subsetLimits_Dbrief,\"uses_data_limits_sources\")).value_counts()\n",
    "\n",
    "# Social\n",
    "countsSocial = pd.DataFrame(extract_sections(subsetSocial,\"uses_biases_sources\")).value_counts()\n",
    "countsSocial_SD = pd.DataFrame(extract_sections(subsetSocial_SD,\"uses_biases_sources\")).value_counts().to_excel(\"bias.xlsx\")\n",
    "countsSocial_Dbrief = pd.DataFrame(extract_sections(subsetSocial_Dbrief,\"uses_biases_sources\")).value_counts()\n",
    "\n",
    "# Collection\n",
    "countsCollection = pd.DataFrame(extract_sections(mergedData,\"collection_explanation_sources\")).value_counts()\n",
    "countsCollection_SD = pd.DataFrame(extract_sections(mergedData_SD,\"collection_explanation_sources\")).value_counts().to_excel(\"collection.xlsx\")\n",
    "countsCollection_Dbrief = pd.DataFrame(extract_sections(mergedData_Dbrief,\"collection_explanation_sources\")).value_counts()\n",
    "# Col Team\n",
    "countsColTeam = pd.DataFrame(extract_sections(subsetCollectionTeam,\"collection_team_demographic_sources\")).value_counts()\n",
    "countsColTeam_SD = pd.DataFrame(extract_sections(subsetCollectionTeam_SD,\"collection_team_demographic_sources\")).value_counts().to_excel(\"colteam.xlsx\")\n",
    "countsColTeam_Dbrief = pd.DataFrame(extract_sections(subsetCollectionTeam_Dbrief,\"collection_team_demographic_sources\")).value_counts()\n",
    "# Col target\n",
    "countsColTarget = pd.DataFrame(extract_sections(subsetCollectionTargetDemographics,\"collection_target_demographics_sources\")).value_counts()\n",
    "countsColTarget_SD = pd.DataFrame(extract_sections(subsetCollectionTargetDemographics_SD,\"collection_target_demographics_sources\")).value_counts().to_excel(\"target.xlsx\")\n",
    "countsColTarget_Dbrief = pd.DataFrame(extract_sections(subsetCollectionTargetDemographics_Dbrief,\"collection_target_demographics_sources\")).value_counts()\n",
    "# Col speakers\n",
    "countsSpeakersTarget = pd.DataFrame(extract_sections(subsetCollectionSpeakersDemographics,\"collection_speakers_demographics_sources\")).value_counts()\n",
    "countsSpeakersTarget_SD = pd.DataFrame(extract_sections(subsetCollectionSpeakersDemographics_SD,\"collection_speakers_demographics_sources\")).value_counts().to_excel(\"speakers.xlsx\")\n",
    "countsSpeakersTarget_Dbrief = pd.DataFrame(extract_sections(subsetCollectionSpeakersDemographics_Dbrief,\"collection_speakers_demographics_sources\")).value_counts()\n",
    "# Col Sources\n",
    "countsCollectionSources = pd.DataFrame(extract_sections(mergedData,\"collection_sources_sources\")).value_counts()\n",
    "countsCollectionSources_SD = pd.DataFrame(extract_sections(mergedData_SD,\"collection_sources_sources\")).value_counts().to_excel(\"sources.xlsx\")\n",
    "countsCollectionSources_Dbrief = pd.DataFrame(extract_sections(mergedData_Dbrief,\"collection_sources_sources\")).value_counts()\n",
    "# Annotation\n",
    "countsAnnotation = pd.DataFrame(extract_sections(mergedData,\"annotation_explanation_sources\")).value_counts()\n",
    "countsAnnotation_SD = pd.DataFrame(extract_sections(mergedData_SD,\"annotation_explanation_sources\")).value_counts().to_excel(\"annotation.xlsx\")\n",
    "countsAnnotation_Dbrief = pd.DataFrame(extract_sections(mergedData_Dbrief,\"annotation_explanation_sources\")).value_counts()\n",
    "\n",
    "# Annotation team\n",
    "countsAnnTeam = pd.DataFrame(extract_sections(subsetAnntationTeam,\"annotation_team_demographi_sources\")).value_counts()\n",
    "countsAnnTeam_SD = pd.DataFrame(extract_sections(subsetAnntationTeam_SD,\"annotation_team_demographi_sources\")).value_counts().to_excel(\"anoteam.xlsx\")\n",
    "countsAnnTeam_Dbrief = pd.DataFrame(extract_sections(subsetAnntationTeam_Dbrief,\"annotation_team_demographi_sources\")).value_counts()\n",
    "\n",
    "# Annotation infrastructure\n",
    "countsAnnInfr =  pd.DataFrame(extract_sections(subsetAnntationInfrastructure,\"annotation_infrastructure_sources\")).value_counts()\n",
    "countssectionsAnnInfr_SD =  pd.DataFrame(extract_sections(subsetAnntationInfrastructure_SD,\"annotation_infrastructure_sources\")).value_counts().to_excel(\"anoinfra.xlsx\")\n",
    "countsAnnInfr_Dbrief =  pd.DataFrame(extract_sections(subsetAnntationInfrastructure_Dbrief,\"annotation_infrastructure_sources\")).value_counts()\n",
    "\n",
    "# Annotation Validation\n",
    "countsAnnVal = pd.DataFrame(extract_sections(subsetAnntationValidation,\"annotation_validation_methods_sources\")).value_counts()\n",
    "countsAnnVal_SD = pd.DataFrame(extract_sections(subsetAnntationValidation_SD,\"annotation_validation_methods_sources\")).value_counts().to_excel(\"anoVali.xlsx\")\n",
    "countsAnnVal_Dbrief = pd.DataFrame(extract_sections(subsetAnntationValidation_Dbrief,\"annotation_validation_methods_sources\")).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sectionMLApproach_SD_clean \u001b[38;5;241m=\u001b[39m \u001b[43mclassifyLabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43msectionsMLapproach_SD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#sectionsMLapproach\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#sectionsMLapproach_SD\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#sectionsMLapproach_DBrief\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m, in \u001b[0;36mclassifyLabels\u001b[0;34m(sections)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx , section \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sections):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m section:\n\u001b[0;32m----> 5\u001b[0m         resultClass  \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43msection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msdataRequiredSections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m resultClass[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.4\u001b[39m:\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchanged\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1260\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1175\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1174\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1175\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    228\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[1;32m    236\u001b[0m }\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1802\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1800\u001b[0m     )\n\u001b[0;32m-> 1802\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1818\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[1;32m   1820\u001b[0m eos_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id)\u001b[38;5;241m.\u001b[39mto(hidden_states\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1528\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1521\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1522\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1523\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1524\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1525\u001b[0m     )\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1528\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1380\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1368\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1369\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         use_cache,\n\u001b[1;32m   1378\u001b[0m     )\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1380\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1393\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:685\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    684\u001b[0m cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    694\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:518\u001b[0m, in \u001b[0;36mBartSdpaAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;66;03m# Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# partitioned across GPUs when using tensor-parallelism.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim)\n\u001b[0;32m--> 518\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m, past_key_value\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/sites/DataPaperAnalysis/DataPaperAnalysis/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sectionMLApproach_SD_clean = classifyLabels(sectionsMLapproach_SD)\n",
    "#sectionsMLapproach\n",
    "#sectionsMLapproach_SD\n",
    "#sectionsMLapproach_DBrief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsSDUsesClassified = pd.DataFrame(classifyLabels(extract_sections(mergedData,\"uses_uses_sources\"))).value_counts()\n",
    "countsSDMLapproachClassified = pd.DataFrame(classifyLabels(extract_sections(subsetML,\"uses_ml_approach_sources\"))).value_counts()\n",
    "countsSDLimitsClassified = pd.DataFrame(classifyLabels(extract_sections(subsetLimits,\"uses_data_limits_sources\"))).value_counts()\n",
    "countsSDSocialClassified = pd.DataFrame(classifyLabels(extract_sections(subsetSocial,\"uses_biases_sources\"))).value_counts()\n",
    "countsSDCollectionClassified = pd.DataFrame(classifyLabels(extract_sections(mergedData,\"collection_explanation_sources\"))).value_counts()\n",
    "countsSDColTeamClassified = pd.DataFrame(classifyLabels(extract_sections(subsetCollectionTeam,\"collection_team_demographic_sources\"))).value_counts()\n",
    "countsSDColTargetClassified = pd.DataFrame(classifyLabels(extract_sections(subsetCollectionTargetDemographics,\"collection_target_demographics_sources\"))).value_counts()\n",
    "countsSDCollectionSourcesClassified = pd.DataFrame(classifyLabels(extract_sections(mergedData,\"collection_sources_sources\"))).value_counts()\n",
    "countsSDAnnotationClassified = pd.DataFrame(classifyLabels(extract_sections(mergedData,\"annotation_explanation_sources\"))).value_counts()\n",
    "countsSDAnnTeamClassified = pd.DataFrame(classifyLabels(extract_sections(subsetAnntationTeam,\"annotation_team_demographi_sources\"))).value_counts()\n",
    "countsSDAnnInfrClassified = pd.DataFrame(classifyLabels(extract_sections(subsetAnntationInfrastructure,\"annotation_infrastructure_sources\"))).value_counts()\n",
    "countsSDAnnValClassified = pd.DataFrame(classifyLabels(extract_sections(subsetAnntationValidation,\"annotation_validation_methods_sources\"))).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extractSources(dataPapers):\n",
    "    for idx, source in dataPapers.iterrows():\n",
    "        row = {\"doi\":source['doi']}\n",
    "        if  isinstance(source[dimension],str):\n",
    "            documents = eval(source[dimension])\n",
    "            for document in documents:\n",
    "                    if dimension == \"uses_uses_sources\":\n",
    "                        sections.insert(0,document[0].metadata['source'])\n",
    "                    else:\n",
    "                        sections.insert(0,document.metadata['source'])\n",
    "            row[dimension+\"_sections\"] = sections\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uses_uses_sources_sections\n",
       "[Data Records, Data Records, Data Records, Data Records]                                                                                                                                              6\n",
       "[Methods, Methods, Methods, Methods]                                                                                                                                                                  5\n",
       "[Methods, Methods, Methods, Code availability]                                                                                                                                                        5\n",
       "[Usage Notes, Usage Notes, Usage Notes, Usage Notes]                                                                                                                                                  5\n",
       "[Code availability, Methods, Data Records, Usage Notes]                                                                                                                                               4\n",
       "                                                                                                                                                                                                     ..\n",
       "[Author Contributions, Additional Information, Methods, Data Records]                                                                                                                                 1\n",
       "[Additional Information, Data Records, Author Contributions, Technical Validation]                                                                                                                    1\n",
       "[Data de-identification, 3., Data Records, Methods]                                                                                                                                                   1\n",
       "[Additional information, Frogs were exposed to Bd or sham-exposed to DSS, Swabs were collected weekly and pre-euthanasia to determine infection intensities via qPCR (Experiment A), Data Records]    1\n",
       "[, , Technical Validation, Methods]                                                                                                                                                                   1\n",
       "Name: count, Length: 3920, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdSection['uses_uses_sources_sections'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_uses = []\n",
    "for index, paper in pdSection.iterrows():\n",
    "    for section in paper['uses_uses_sources_sections']:\n",
    "        sources_uses.append(section)\n",
    "pdSourcesUses = pd.DataFrame(sources_uses)\n",
    "pdSourcesUses.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(pdSourcesUses.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source0 = unserialized_sources[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
